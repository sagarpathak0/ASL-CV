# ğŸ¤– ASL CNN Classification System
- âœ… **29-class ASL recognition** (A-Z + del, nothing, space)
- âš¡ **32x faster loading** (569+ images/sec vs 17/sec)
- ğŸ¯ **Full dataset by default** for maximum accuracy (90%+)
- ğŸ“ˆ **Real-time progress** with ETA estimates
- ğŸ’¾ **Checkpoint system** - pause/resume training anytime
- ğŸ† **Auto-save best models** with epoch tracking
- ğŸ’¾ **Auto-save models** with testing on sample imagesgh-performance CNN** built from scratch with **NumPy** for **American Sign Language** alphabet recognition. Supports **29 ASL classes** (A-Z + del, nothing, space) with **optimized parallel loading** and **full dataset training by default**.

## ğŸš€ Quick Start

### **Default Training (Full Dataset - 45-60 minutes, ~90%+ accuracy)**
```bash
python train.py
```

### **Quick Test (30 seconds)**
```bash
python train.py --max_samples 50 --epochs 1
```

### **Fast Training (2-3 minutes, ~75% accuracy)**
```bash
python train.py --max_samples 200 --epochs 3
```

### **Balanced Training (10-15 minutes, ~85% accuracy)**
```bash
python train.py --max_samples 1000 --epochs 5
```

### **Resume Training (continue from checkpoint)**
```bash
# Resume from latest checkpoint
python train.py --resume latest --epochs 10

# Resume from specific epoch
python train.py --resume models/epoch_5 --epochs 15
```

## ğŸ“Š Key Features

- âœ… **29-class ASL recognition** (A-Z + del, nothing, space)
- âš¡ **32x faster loading** (569+ images/sec vs 17/sec)
- ğŸ¯ **Smart defaults** for 2-3 minute training sessions
- ğŸ“ˆ **Real-time progress** with ETA estimates
- ï¿½ **Checkpoint system** - pause/resume training anytime
- ğŸ† **Auto-save best models** with epoch tracking
- ğŸ’¾ **Auto-save models** with testing on sample images

## âš¡ Performance Optimizations

| Mode | Command | Time | Accuracy | Use Case |
|------|---------|------|----------|----------|
| **Quick Test** | `--max_samples 50 --epochs 1` | 30s | 60-70% | Development |
| **Fast Training** | `--max_samples 200 --epochs 3` | 2-3min | 70-80% | Quick validation |
| **Balanced** | `--max_samples 1000 --epochs 5` | 10-15min | 80-90% | Testing |
| **Default (Full)** | `python train.py` | 45-60min | 90-95% | Production |

## ğŸ® Command Options

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--max_samples` | None (full dataset) | Samples per class (None=full dataset) |
| `--epochs` | 5 | Training epochs |
| `--lr` | 0.01 | Learning rate |
| `--batch_size` | 32 | Batch size |
| `--val_split` | 0.2 | Validation split ratio |
| `--resume` | None | Resume training (latest or models/epoch_N) |
| `--start_epoch` | 1 | Starting epoch number |

## ğŸ”§ Setup

1. **Install dependencies:**
```bash
pip install numpy opencv-python
```

2. **Download ASL Dataset** and place in:
```
ASL_Alphabet_Dataset/
â”œâ”€â”€ asl_alphabet_train/  # Training folders (A/, B/, C/, ...)
â””â”€â”€ asl_alphabet_test/   # Test images
```

3. **Run training:**
```bash
python train.py
```

## ï¿½ Checkpoint System

### **Automatic Saving**
The model automatically saves checkpoints after each epoch:
```
models/
â”œâ”€â”€ epoch_1/          # Checkpoint after epoch 1
â”œâ”€â”€ epoch_2/          # Checkpoint after epoch 2
â”œâ”€â”€ latest/           # Always points to most recent
â”œâ”€â”€ best/            # Best performing model
â””â”€â”€ *.npy           # Legacy format files
```

### **Resume Commands**
```bash
# Resume from latest checkpoint
python train.py --resume latest --epochs 10

# Resume from specific epoch  
python train.py --resume models/epoch_3 --epochs 15

# Resume with different settings
python train.py --resume latest --lr 0.005 --epochs 20
```

### **Checkpoint Contents**
- `conv_filters.npy` - Convolutional weights
- `softmax_weights.npy` - Output layer weights
- `softmax_biases.npy` - Output layer biases  
- `metadata.json` - Training metrics & info

## ï¿½ğŸ“ˆ What You'll See

```
ğŸš€ Loading ASL dataset with detailed progress tracking...
ğŸ” Scanning dataset directories...
   ğŸ“ A: 8458 files found â†’ using 200
   ğŸ“ B: 8309 files found â†’ using 200
   ...
âš¡ Loading 29 classes in parallel...
ğŸ“ˆ Progress by class:
   âœ… A: 200 images loaded
   ğŸ”„ Overall progress: 3.4% (1/29 classes loaded)
   ...

ğŸ‰ Loading completed successfully!
ğŸ“Š Performance Summary:
   â±ï¸  Total time: 2.1s
   ğŸ“ˆ Loading speed: 2,761 images/second
   
ğŸš€ Starting training session...
ğŸ“Š Batch 1/15 |â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 6.7% | Train Loss: 3.24 | Train Acc: 0.16
ğŸ“Š Batch 2/15 |â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘| 13.3% | Train Loss: 3.18 | Train Acc: 0.22
...
âœ… Epoch 1 completed in 12.3s
ğŸ” Evaluating on validation set...
ğŸ“Š Validation Results: â€¢ Val Accuracy: 0.7245 (72.5%)
ğŸ’¾ Saving checkpoint...
   ï¿½ New best model saved (accuracy: 0.7245)
âœ… Checkpoint saved: models\epoch_1

ï¿½ğŸ‰ TRAINING COMPLETED! ğŸ‰
ğŸ’¾ CHECKPOINTS SAVED:
   ğŸ“ Latest checkpoint: models/latest/
   ğŸ† Best model: models/best/
   ğŸ“‚ All epochs: models/epoch_*/
ğŸ”„ RESUME TRAINING:
   To continue: python train.py --resume latest --epochs 10
ğŸ’¾ Model weights saved to 'models'
ğŸ§ª Testing on sample images...
ğŸ“¸ Test 1/5: A_test.jpg â†’ Prediction: A (confidence: 0.89)
```

## ğŸ” Troubleshooting

| Issue | Solution |
|-------|----------|
| **Training too slow** | Use `--max_samples 200` for faster training |
| **Out of memory** | Use `--batch_size 16` or `--max_samples 100` |
| **Low accuracy** | Use full dataset: `python train.py` or increase `--epochs` |
| **Dataset not found** | Check `ASL_Alphabet_Dataset/` folder structure |
| **Resume failed** | Check if `models/` directory exists |
| **Training interrupted** | Use `--resume latest` to continue |
| **Want quick test** | Use `--max_samples 50 --epochs 1` |

## ğŸ“š Documentation

- **ğŸ“– [DOCUMENTATION.md](DOCUMENTATION.md)** - Complete technical guide with advanced usage
- **âš¡ [QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - Essential commands and troubleshooting
- **ğŸ—ï¸ Architecture:** CNN with 8â†’16 conv filters, 39K parameters
- **ğŸ¯ Classes:** 29 ASL signs (A-Z, del, nothing, space)
- **âš¡ Speed:** 569-1096 images/sec loading, 2-3min default training

---

**ğŸ‰ Ready to train!** Start with `python train.py` and adjust parameters based on your needs.
